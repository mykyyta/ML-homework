{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f85cd77-4b7d-490d-9b1b-06b13548ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4ccd9b8a3647baa677b67946aab84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce445c9-c7f4-4c8f-8017-77cc576ed46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4b430e-8bf7-4344-9ce5-919180bc959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c5ce7a-5b63-4bc8-ac0f-070fd24388e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b999f39d-d87e-4041-aa84-6bcfc97bd80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2) (25000, 2)\n"
     ]
    }
   ],
   "source": [
    "train = ds['train'].to_pandas()\n",
    "test = ds['test'].to_pandas()\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49a7112-c41f-40d7-a0a2-39a8890bbbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I would put this at the top of my list of film...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whoever wrote the screenplay for this movie ob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When I first saw a glimpse of this movie, I qu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Who are these \"They\"- the actors? the filmmake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is said to be a personal film for Peter B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0\n",
       "5  I would put this at the top of my list of film...      0\n",
       "6  Whoever wrote the screenplay for this movie ob...      0\n",
       "7  When I first saw a glimpse of this movie, I qu...      0\n",
       "8  Who are these \"They\"- the actors? the filmmake...      0\n",
       "9  This is said to be a personal film for Peter B...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe2492-51c6-4e88-b59f-2cd2475fdfe8",
   "metadata": {},
   "source": [
    "### Модель 1: Naive bayes + vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79afe6d-270b-4aa1-99f1-0b76cf5631b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train['text'])\n",
    "X_test = vectorizer.transform(test['text'])\n",
    "\n",
    "y_train = train['label']\n",
    "y_test = test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463716c1-5362-45e0-bc03-e6500659792d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d44278-ebda-4d43-9404-f2537970e4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3989209a-6181-44b9-897b-fa47c8dbeb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03e9e5db-b415-44ab-8dc3-7d2816cbb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_cv(model, param_grid, x_train, y_train):\n",
    "    grid_search = RandomizedSearchCV(model, param_grid, cv=5, scoring='accuracy', n_iter=10)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    print('model {} best accuracy score is {}'.format(model.__class__.__name__, grid_search.best_score_))\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa79a1f5-eb6a-43d5-a60f-b8c568767f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model MultinomialNB best accuracy score is 0.7990400000000001\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha':[0.001, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.5, 2, 5]}\n",
    "model = MultinomialNB()\n",
    "best_model = randomized_cv(model, param_grid, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "617ec854-2cb7-441a-83e0-9149a88c0bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83     12500\n",
      "           1       0.86      0.76      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.82      0.82      0.82     25000\n",
      "weighted avg       0.82      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa30aa-eed3-41e6-9801-cf313b017fc4",
   "metadata": {},
   "source": [
    "### Модель 2: doc2vec з gensimа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48032c56-1489-43b8-ad84-f9aff89df51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]+')\n",
    "\n",
    "train['tokenized'] = train['text'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "test['tokenized'] = test['text'].apply(lambda x: tokenizer.tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb042a64-a8ee-43e6-b8d9-a85a0bd0ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [i, rented, i, am, curious, -, yellow, from, m...\n",
       "1    [\", i, am, curious, :, yellow, \", is, a, risib...\n",
       "2    [if, only, to, avoid, making, this, type, of, ...\n",
       "3    [this, film, was, probably, inspired, by, goda...\n",
       "4    [oh, ,, brother, ..., after, hearing, about, t...\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokenized'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a9d73f7-134c-458a-b340-9e7567081911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "tagged_data = [TaggedDocument(words=row['tokenized'], tags=[str(index)]) for index, row in train.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5b0d98a-339d-478d-92db-a4e63395d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(tagged_data, vector_size=50, window=2, min_count=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca291de2-10ef-40ac-b1f4-bbf5b2aa669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['doc_vector'] = train['tokenized'].apply(lambda x: model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4b7829b-3f46-4183-bb2a-a2f2622f6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['doc_vector'] = test['tokenized'].apply(lambda x: model.infer_vector(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff49e60b-2747-4ac8-910d-55e3420353ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.70%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78     12500\n",
      "           1       0.80      0.71      0.75     12500\n",
      "\n",
      "    accuracy                           0.77     25000\n",
      "   macro avg       0.77      0.77      0.77     25000\n",
      "weighted avg       0.77      0.77      0.77     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = list(train['doc_vector'])\n",
    "y_train = train['label']\n",
    "X_test = list(test['doc_vector'])\n",
    "y_test = test['label']\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
